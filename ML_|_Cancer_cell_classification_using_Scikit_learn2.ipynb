{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq+DnCxmHQjsG2TLBt3APQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evanssamwel/Machine-Learning/blob/main/ML_%7C_Cancer_cell_classification_using_Scikit_learn2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML | Cancer cell classification using Scikit-learn\n",
        "Machine learning is used in solving real-world problems including medical diagnostics. One such application is classifying cancer cells based on their features and determining whether they are 'malignant' or 'benign'. In this article, we will use Scikit-learn to build a classifier for cancer cell detection.\n",
        "\n",
        "Overview of the Dataset\n",
        "The Breast Cancer Wisconsin (Diagnostic) dataset consists of:\n",
        "\n",
        "569 instances (tumor samples)\n",
        "30 attributes (features), including radius, texture, perimeter, and area of tumors\n",
        "Two classification labels:\n",
        "0 (Malignant) : Cancerous\n",
        "1 (Benign) : Non-cancerous\n",
        "We will use these features to train and evaluate our machine learning model.\n",
        "\n",
        "Implementing Cancer cell classification in Python\n",
        "Below is the step-by-step implementation:\n",
        "\n",
        "1. Importing Necessary Modules and Dataset\n",
        "We will use numpy, matplotlib and scikit learn for this.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "2. Loading the Dataset into a Variable\n",
        "For this project, we will use the Breast Cancer Wisconsin (Diagnostic) dataset which is available in Scikit-learnâ€™s datasets module. We use the load_breast_cancer() function to load the dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = load_breast_cancer()\n",
        "3. Exploring the Dataset\n",
        "Before training the model let's examine the dataset. This helps us understand how the data is structured and labeled. We will use pandas module to create a dataframe to simplify this process. We will use df.sample() function to fetch some random records from the data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df.sample(5)\n",
        "Output:\n",
        "\n",
        "saMPLE\n",
        "Dataset\n",
        "To explore the data types of the columns in our dataset we will use the df.info() function. It will help us to understand the categorical and numerical columns in our dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df.info()\n",
        "Output:\n",
        "\n",
        "info\n",
        "Dataset Info\n",
        "To investigate the numerical columns we will use the df.describe() function. This function provides key summary statistics such as the mean, standard deviation, minimum and maximum values for each numerical column. It helps us understand the distribution and scale of the data which is crucial for preprocessing and model performance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df.describe()\n",
        "Output:\n",
        "\n",
        "describe\n",
        "Described Dataset\n",
        "We must also analyze data.target to understand the distribution of malignant and benign cases as class imbalance can affect model performance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df2=pd.DataFrame(data.target,columns=['target'])\n",
        "df2.sample(5)\n",
        "Output:\n",
        "\n",
        "tar\n",
        "Data Distribution\n",
        "Plotting an pie chart will help us understand the distribution of the target values.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class_counts=df2[\"target\"].value_counts()\n",
        "plt.pie(class_counts, labels=class_counts.index, autopct='%1.2f%%', colors=['red', 'green'])\n",
        "Output:\n",
        "\n",
        "dist_pie\n",
        "Pie Chart\n",
        "Usually this type of dataset is considered imbalanced. A common threshold is when the minority class constitutes less than 30% of the total samples. However in this case its almost 38% which is acceptable. Incases of imbalances we can use techniques like oversampling, undersampling or class weighting.\n",
        "\n",
        "4. Splitting the Data into Training and Testing Sets\n",
        "To evaluate our classifier we split the dataset into training and test sets using train_test_split(). Here 33% of the data is used for testing while the remaining 67% is used for training.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state=42)\n",
        "5. Building and Training the Model\n",
        "We use Naive Bayes algorithm which is effective for binary classification tasks. The fit() function trains the model on the training dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "Output:\n",
        "\n",
        "Screenshot-2025-04-13-173333\n",
        "Model Training\n",
        "6. Making Predictions\n",
        "Now we use our trained model to predict the classification of cancer cells in the test set. The output is an array of 0s and 1s representing predicted tumor classifications.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred[:10])\n",
        "Output:\n",
        "\n",
        "[1, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
        "\n",
        "7. Evaluating Model Accuracy\n",
        "To measure how well our model performs we will compare its predictions with the actual labels to calculate its accuracy. We will use accuracy_score from the sklearn.metrics library.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "Output:\n",
        "\n",
        "Model Accuracy: 94.15%\n",
        "\n",
        "This means our Naive Bayes classifier is 94.15% accurate in predicting whether a tumor is malignant or benign meaning our model is working fine and can be used for medical diagnostics."
      ],
      "metadata": {
        "id": "yv-HnwgwPVQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cn5JYAQPS-EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jN1o9hVJPZjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: upload dataset\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "-mIlxQEiPgEA",
        "outputId": "86b80c24-abb0-4106-db00-93185e26bc32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-34df13dc-f822-466f-a6a2-1294e82c55d1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-34df13dc-f822-466f-a6a2-1294e82c55d1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wdbc.data to wdbc.data\n",
            "Saving wdbc.names to wdbc.names\n",
            "User uploaded file \"wdbc.data\" with length 124103 bytes\n",
            "User uploaded file \"wdbc.names\" with length 4708 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i  want to  the load dataset into a variable , specifically the wdbc.data csv  data = load_breast_cancer()\n",
        "\n",
        "# Assuming the uploaded file is named 'wdbc.data'\n",
        "filename = list(uploaded.keys())[0] # Get the name of the uploaded file\n",
        "data = pd.read_csv(filename, header=None) # Load the data into a pandas DataFrame\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtSvAQe-QVO1",
        "outputId": "c35e7909-cfa3-43fd-a90d-bea8cd952721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0  1      2      3       4       5        6        7       8   \\\n",
            "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
            "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
            "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
            "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
            "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
            "\n",
            "        9   ...     22     23      24      25      26      27      28      29  \\\n",
            "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
            "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
            "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
            "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
            "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
            "\n",
            "       30       31  \n",
            "0  0.4601  0.11890  \n",
            "1  0.2750  0.08902  \n",
            "2  0.3613  0.08758  \n",
            "3  0.6638  0.17300  \n",
            "4  0.2364  0.07678  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i want to do the following ,,Splitting the Data into Training and Testing Sets   Here 33% of the data is used for testing while the remaining 67% is used for training.Building and Training the Model\n",
        "# We use Naive Bayes algorithm which is effective for binary classification tasks.  Making Predictions\n",
        "# Now we use our trained model to predict the classification of cancer cells in the test set. The output is an array of 0s and 1s representing predicted tumor classifications\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state=42)\n",
        "\n",
        "# Build and Train the Model\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gJhMnrcR1qT",
        "outputId": "6d128dc3-c43d-44c2-effa-8971b6705b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 0 0 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:  Evaluating Model Accuracy\n",
        "# To measure how well our model performs we will compare its predictions with the actual labels to calculate its accuracy.\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BWdeB9uSKBw",
        "outputId": "d4a6dc7d-848e-464a-930a-8c3828da7815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 94.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML | Kaggle Breast Cancer Wisconsin Diagnosis using KNN and Cross Validation\n",
        "Last Updated\n",
        "Dataset : It is given by Kaggle from UCI Machine Learning Repository, in one of its challenges. It is a dataset of Breast Cancer patients with Malignant and Benign tumor. K-nearest neighbour algorithm is used to predict whether is patient is having cancer (Malignant tumour) or not (Benign tumour). Implementation of KNN algorithm for classification. Code : Importing Libraries\n",
        "\n",
        "# performing linear algebra\n",
        "import numpy as np\n",
        "\n",
        "# data processing\n",
        "import pandas as pd\n",
        "\n",
        "# visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "Code : Loading dataset\n",
        "\n",
        "df = pd.read_csv(\"..\\\\breast-cancer-wisconsin-data\\\\data.csv\")\n",
        "\n",
        "print (data.head)\n",
        "Output :Code: Data Info\n",
        "\n",
        "df.info()\n",
        "Output :\n",
        "RangeIndex: 569 entries, 0 to 568\n",
        "Data columns (total 33 columns):\n",
        "id                         569 non-null int64\n",
        "diagnosis                  569 non-null object\n",
        "radius_mean                569 non-null float64\n",
        "texture_mean               569 non-null float64\n",
        "perimeter_mean             569 non-null float64\n",
        "area_mean                  569 non-null float64\n",
        "smoothness_mean            569 non-null float64\n",
        "compactness_mean           569 non-null float64\n",
        "concavity_mean             569 non-null float64\n",
        "concave points_mean        569 non-null float64\n",
        "symmetry_mean              569 non-null float64\n",
        "fractal_dimension_mean     569 non-null float64\n",
        "radius_se                  569 non-null float64\n",
        "texture_se                 569 non-null float64\n",
        "perimeter_se               569 non-null float64\n",
        "area_se                    569 non-null float64\n",
        "smoothness_se              569 non-null float64\n",
        "compactness_se             569 non-null float64\n",
        "concavity_se               569 non-null float64\n",
        "concave points_se          569 non-null float64\n",
        "symmetry_se                569 non-null float64\n",
        "fractal_dimension_se       569 non-null float64\n",
        "radius_worst               569 non-null float64\n",
        "texture_worst              569 non-null float64\n",
        "perimeter_worst            569 non-null float64\n",
        "area_worst                 569 non-null float64\n",
        "smoothness_worst           569 non-null float64\n",
        "compactness_worst          569 non-null float64\n",
        "concavity_worst            569 non-null float64\n",
        "concave points_worst       569 non-null float64\n",
        "symmetry_worst             569 non-null float64\n",
        "fractal_dimension_worst    569 non-null float64\n",
        "Unnamed: 32                0 non-null float64\n",
        "dtypes: float64(31), int64(1), object(1)\n",
        "memory usage: 146.8+ KB\n",
        "Code: We are dropping columns - 'id' and 'Unnamed: 32' as they have no role in prediction\n",
        "\n",
        "df.drop(['Unnamed: 32', 'id'], axis = 1)\n",
        "print(df.shape)\n",
        "Output:\n",
        "(569, 31)\n",
        "Code: Converting the diagnosis value of M and B to a numerical value where M (Malignant) = 1 and B (Benign) = 0\n",
        "\n",
        "def diagnosis_value(diagnosis):\n",
        "    if diagnosis == 'M':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df['diagnosis'] = df['diagnosis'].apply(diagnosis_value)\n",
        "Code :\n",
        "\n",
        "sns.lmplot(x = 'radius_mean', y = 'texture_mean', hue = 'diagnosis', data = df)\n",
        "Output:\n",
        "\n",
        "Code :\n",
        "\n",
        "sns.lmplot(x ='smoothness_mean', y = 'compactness_mean',\n",
        "           data = df, hue = 'diagnosis')\n",
        "Output:Code : Input and Output data\n",
        "\n",
        "X = np.array(df.iloc[:, 1:])\n",
        "y = np.array(df['diagnosis'])\n",
        "Code : Splitting data to training and testing\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size = 0.33, random_state = 42)\n",
        "Code : Using Sklearn\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 13)\n",
        "knn.fit(X_train, y_train)\n",
        "Output:\n",
        "KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
        "             metric='minkowski', metric_params=None,\n",
        "             n_jobs=None, n_neighbors=13, p=2,\n",
        "             weights='uniform')\n",
        "Code : Prediction Score\n",
        "\n",
        "knn.score(X_test, y_test)\n",
        "Output:\n",
        "0.9627659574468085\n",
        "Code : Performing Cross Validation\n",
        "\n",
        "neighbors = []\n",
        "cv_scores = []\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# perform 10 fold cross validation\n",
        "for k in range(1, 51, 2):\n",
        "    neighbors.append(k)\n",
        "    knn = KNeighborsClassifier(n_neighbors = k)\n",
        "    scores = cross_val_score(\n",
        "        knn, X_train, y_train, cv = 10, scoring = 'accuracy')\n",
        "    cv_scores.append(scores.mean())\n",
        "Code : Misclassification error versus k\n",
        "\n",
        "MSE = [1-x for x in cv_scores]\n",
        "\n",
        "# determining the best k\n",
        "optimal_k = neighbors[MSE.index(min(MSE))]\n",
        "print('The optimal number of neighbors is % d ' % optimal_k)\n",
        "\n",
        "# plot misclassification error versus k\n",
        "plt.figure(figsize = (10, 6))\n",
        "plt.plot(neighbors, MSE)\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Misclassification Error')\n",
        "plt.show()\n",
        "Output:\n",
        "The optimal number of neighbors is 13\n",
        "\n"
      ],
      "metadata": {
        "id": "MR58NxwNS_N5"
      }
    }
  ]
}